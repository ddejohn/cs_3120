{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 3120 Machine Learning HW1\n",
    "\n",
    "Devon DeJohn, Spring 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from source import k_nearest_neighbors\n",
    "model = k_nearest_neighbors.Model(\"../data/animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import pathlib\n",
    "import random\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report as crep\n",
    "from itertools import product\n",
    "from tabulate import tabulate\n",
    "```\n",
    "\n",
    "## Train, Test, Validate\n",
    "\n",
    "My default model's parameters are slightly different than `sklearn`'s model, as noted in the initial call to `super().__init__()`:\n",
    "\n",
    "```python\n",
    "DEFAULT = {\n",
    "    \"n_neighbors\": 3,\n",
    "    \"metric\": \"manhattan\",\n",
    "    \"weights\": \"distance\",\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "class Model(KNeighborsClassifier):\n",
    "    \"\"\"A container for a KNN classifier\"\"\"\n",
    "    def __init__(self, path: str):\n",
    "        super().__init__(**DEFAULT)\n",
    "        self.dims = (16,16)\n",
    "        self.labels = {}\n",
    "        self.path = path\n",
    "        self.parts = [\"train\", \"test\", \"validate\"]\n",
    "        self.load_data()\n",
    "        self.fit(self.train.X, self.train.Y)\n",
    "    # end\n",
    "```\n",
    "\n",
    "I also decided to implement my own version of `train_test_split` that supports multiple partitions, not just two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Partition 0: 'train'\n",
      "       size: 2100 / 3000\n",
      "       pcnt: 70.0 %\n",
      "\n",
      "Partition 1: 'test'\n",
      "       size: 600 / 3000\n",
      "       pcnt: 20.0 %\n",
      "\n",
      "Partition 2: 'validate'\n",
      "       size: 300 / 3000\n",
      "       pcnt: 10.0 %\n"
     ]
    }
   ],
   "source": [
    "model.datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K=3, using the $\\ell_1$-norm\n",
    "\n",
    "For `n_neighbors=3`, using the `manhattan` distance metric, or the $\\ell_1$-norm, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.49      0.44      0.46       202\n",
      "         dog       0.47      0.57      0.52       223\n",
      "       panda       0.73      0.63      0.68       175\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.56      0.54      0.55       600\n",
      "weighted avg       0.55      0.54      0.54       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining\n",
    "\n",
    "I added the ability to retrain the model directly through the `Model` type by making `sklearn.KNeighborsClassifier` a super class of `Model`, so that the classifier's attributes are accessible via the `Model` type.\n",
    "\n",
    "## Performance\n",
    "\n",
    "Taking the cartesian product of these parameters, we can retrain our model on every combination and measure the mean accuracy:\n",
    "\n",
    "```python\n",
    "dims = [8, 16, 32, 64]\n",
    "neighbors = [3, 5, 7, 9]\n",
    "metrics = [\"manhattan\", \"euclidean\"]\n",
    "weights = [\"uniform\", \"distance\"]\n",
    "```\n",
    "\n",
    "Each time `Model.retrain()` is called, the seed for the `random` module is reset, so the testing data are the same across each run.\n",
    "\n",
    "Each subplot below represents a distance metric (tabular), and a weighting algorithm (columnar). The horizontal axis of each subplot represents the pixel dimensions of the rescaled image data, and the vertical axis represents the number of neighbors counted in voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.cycle_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the tabular data above, we achieved the highest accuracy with `9` neighbors, using the inverse of the `distance` as a vote weight, measured using the $\\ell_1$-norm, for a `16 x 16`-pixel image.\n",
    "\n",
    "In general, $k$-nearest neighbors is a poor choice for naive image classification. Potential improvements could include a very rudimentary face recognition algorithm which would isolate the head/face of the animal in the image, crop the image so that the face/head is the only portion shown, then resize.\n",
    "\n",
    "Even then, the variation in the image data is highly dependent on lighting, camera angle, and many other factors which can't be accounted for simply by analyzing the pixel intensities themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.retrain((16,16), {\"n_neighbors\": 9, \"metric\": \"manhattan\", \"weights\": \"distance\", \"n_jobs\": -1})\n",
    "model.report(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
