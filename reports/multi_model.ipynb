{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 3120 Machine Learning Midterm\n",
    "Devon DeJohn, Spring 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from source import multi_model as mm\n",
    "mnist = mm.Model(\"../data/mnist.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset\n",
    "\n",
    "### Partitions\n",
    "```\n",
    "Partition 0:\n",
    "        name: 'train'\n",
    "        size: 29400 / 42000\n",
    "        pcnt: 70.0 %\n",
    "\n",
    "Partition 1:\n",
    "        name: 'test'\n",
    "        size: 8400 / 42000\n",
    "        pcnt: 20.0 %\n",
    "\n",
    "Partition 2:\n",
    "        name: 'validate'\n",
    "        size: 4200 / 42000\n",
    "        pcnt: 10.0 %\n",
    "```\n",
    "\n",
    "### Scores\n",
    "I used three different models for classification: support vector machine, decision tree, k-nearest neighbors, and logistic regression.\n",
    "\n",
    "I used a validation set to test the different models by varying the number of principal components. I did also do an initial test of scaled vs. unscaled data, but found that all models performed significantly better on scaled data.\n",
    "\n",
    "Here are the results from the four different models, with PCA performed with values of `n = 8, 16, 32, 64`. For the `KNN` model, I ran a separate round of tests and arrived at the parameters shown below with the best performance.\n",
    "\n",
    "Here are the models (and the parameters) I used:\n",
    "\n",
    "```python\n",
    "\"support vector machine\": SVC(),\n",
    "\"k-nearest neighbors\": KNeighborsClassifier(weights=\"distance\", metric=\"manhattan\", n_jobs=-1),\n",
    "\"logistic regression\": LogisticRegression(max_iter=1000),\n",
    "\"decision tree\": DecisionTreeClassifier()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUPPORT VECTOR MACHINE\n",
      "         PCA 8: 0.84429\n",
      "        PCA 16: 0.47167\n",
      "        PCA 32: 0.55429\n",
      "        PCA 64: 0.55548\n",
      "\n",
      "K-NEAREST NEIGHBORS\n",
      "         PCA 8: 0.82857\n",
      "        PCA 16: 0.57024\n",
      "        PCA 32: 0.52071\n",
      "        PCA 64: 0.4881\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "         PCA 8: 0.74\n",
      "        PCA 16: 0.52238\n",
      "        PCA 32: 0.50476\n",
      "        PCA 64: 0.435\n",
      "\n",
      "DECISION TREE\n",
      "         PCA 8: 0.70381\n",
      "        PCA 16: 0.4331\n",
      "        PCA 32: 0.39405\n",
      "        PCA 64: 0.36857\n"
     ]
    }
   ],
   "source": [
    "results = mm.compare_models(mnist)\n",
    "for mdl, res in results.items():\n",
    "    print(f\"\\n{mdl.upper()}\\n\" + \"\\n\".join(res))\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosing the best model\n",
    "The model that performs best out of the **very** limited set of hyperparameters explored above was the support vector machine with a principal component analysis done using 8 principal components, and where the data was scaled using `sklearn.preprocessing`. Here is the classification report for the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       835\n",
      "           1       0.96      0.98      0.97       919\n",
      "           2       0.90      0.92      0.91       862\n",
      "           3       0.83      0.79      0.81       839\n",
      "           4       0.76      0.78      0.77       827\n",
      "           5       0.87      0.85      0.86       771\n",
      "           6       0.95      0.94      0.94       821\n",
      "           7       0.92      0.89      0.90       916\n",
      "           8       0.82      0.84      0.83       810\n",
      "           9       0.73      0.70      0.71       800\n",
      "\n",
      "    accuracy                           0.87      8400\n",
      "   macro avg       0.86      0.86      0.86      8400\n",
      "weighted avg       0.87      0.87      0.87      8400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = mm.SVC()\n",
    "xtrain = mm.process_data(mnist.train.X, 8)\n",
    "ytrain = mnist.train.Y\n",
    "\n",
    "xtest = mm.process_data(mnist.test.X, 8)\n",
    "ytest = mnist.test.Y\n",
    "\n",
    "svm.fit(xtrain, ytrain)\n",
    "mnist.report(svm, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Classifier: SVM\n",
    "The classifier that performed the best for the `MNIST` dataset was the support vector machine, but not by much as can be seen below, where I test the `KNN` model using the same PCA feature reduction. Due to the relatively simple task of classifying handwritten digits (as opposed to more complex images like animals), all of these classifiers tend to perform similarly. However, there are just too many hyperparameters to make any sort of substantial claim about the performance of any particular model on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       835\n",
      "           1       0.96      0.98      0.97       919\n",
      "           2       0.91      0.90      0.91       862\n",
      "           3       0.82      0.74      0.78       839\n",
      "           4       0.73      0.77      0.75       827\n",
      "           5       0.85      0.77      0.81       771\n",
      "           6       0.93      0.95      0.94       821\n",
      "           7       0.91      0.89      0.90       916\n",
      "           8       0.77      0.82      0.79       810\n",
      "           9       0.69      0.68      0.68       800\n",
      "\n",
      "    accuracy                           0.85      8400\n",
      "   macro avg       0.85      0.85      0.85      8400\n",
      "weighted avg       0.85      0.85      0.85      8400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = mm.KNeighborsClassifier(weights=\"distance\", metric=\"manhattan\", n_jobs=-1)\n",
    "xtrain = mm.process_data(mnist.train.X, 8)\n",
    "ytrain = mnist.train.Y\n",
    "\n",
    "xtest = mm.process_data(mnist.test.X, 8)\n",
    "ytest = mnist.test.Y\n",
    "\n",
    "knn.fit(xtrain, ytrain)\n",
    "mnist.report(knn, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
